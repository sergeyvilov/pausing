{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b06c775e-48f1-4419-bcff-592f9ff24761",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/envs/jupyterhub/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "#import shap\n",
    "import os\n",
    "import time\n",
    "import builtins\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge as Model\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416ae037-3a4b-4cb5-90f2-250b6baf4a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_dir = '/s/project/mll/sergey/pausing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb992c3-eb3a-4bf6-b672-4513fa7b2dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = project_dir + 'linear_regression'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb7e37e-90db-4d84-a6a1-3132853df43a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hepg2_df = pd.read_csv(project_dir + 'data/individual.HepG2.all.features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec2c9fb-becf-4101-8b56-6c8e3b010d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k562_df = pd.read_csv(project_dir + 'data/individual.K562.all.features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14514122-09ae-4e42-8a97-81d850b416b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print(*args, **kwargs):\n",
    "    '''\n",
    "    Redefine print function for logging\n",
    "    '''\n",
    "    now = time.strftime(\"[%Y/%m/%d-%H:%M:%S]-\", time.localtime()) #place current time at the beggining of each printed line\n",
    "    builtins.print(now, *args, **kwargs)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "877fa8ea-a95e-4601-be58-8cfa60613a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "\n",
    "    df = df.fillna(df.median())\n",
    "\n",
    "    df.loc[np.isfinite(df['tx.ex.ratio'])==False,'tx.ex.ratio'] = 1\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffe84704-f843-49d5-b9f5-7de4d286fd57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_features(X_train, X_test):\n",
    "\n",
    "    zero_variance_columns = X_train.columns[(X_train.std()==0).values]\n",
    "    \n",
    "    X_train = X_train.drop(columns=zero_variance_columns)\n",
    "    X_test = X_test.drop(columns=zero_variance_columns)\n",
    "\n",
    "    mean = X_train.mean()\n",
    "    std = X_train.std()\n",
    "    \n",
    "    X_train_norm = (X_train-mean)/std\n",
    "    \n",
    "    X_test_norm = (X_test-mean)/std\n",
    "    \n",
    "    return X_train_norm, X_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f757b082-5c95-4bf2-ac68-b66345a3fb27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hpp_search(X_train, y_train):\n",
    "    \n",
    "    model = Model(random_state=1)\n",
    "\n",
    "    parameters = {'alpha':np.arange(1,10000,100)}\n",
    "\n",
    "    clf = GridSearchCV(model, parameters, verbose=0)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9de37eb-1737-4fda-968e-8d70fe2a7693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model, output_name):\n",
    "    \n",
    "    output_path = output_dir + '/' + output_name + '.pickle'\n",
    "    \n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(model,f)\n",
    "        \n",
    "    print('Model saved to: ', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "893c2310-93ad-4a80-bf7b-7c6d18628488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shap_values(model, X_test, output_name):\n",
    "    \n",
    "    print('Computing Shapley values...')\n",
    "    \n",
    "    #X100 = shap.utils.sample(X_test, 100)\n",
    "\n",
    "    #explainer = shap.Explainer(model.predict, X100, max_evals = 2 * X100.shape[1] + 1)\n",
    "    \n",
    "    #shap_values = explainer(X_test, silent=True)\n",
    "    \n",
    "    shap_values = (model.coef_ * X_test) - (model.coef_ * X_test).mean()\n",
    "    \n",
    "    shap_values = pd.DataFrame(shap_values.values, index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "    ##proteins = [x.split('.')[1] if 'chip' in x or 'clip' in x else 'NA' for x in X_test.columns]\n",
    "\n",
    "    ##shap_df = pd.DataFrame({'protein':proteins, 'shap_values_sum':np.sum(shap_values.values,axis=0)})\n",
    "\n",
    "    ##shap_df.groupby('protein').sum().to_csv(output_dir + '/' + output_name + '.csv')\n",
    "    \n",
    "    output_path = output_dir + '/' + output_name + '.csv.gz'\n",
    "    \n",
    "    shap_values.to_csv(output_path)\n",
    "    \n",
    "    print('Shapley values saved to: ', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e992e99a-f45c-4d70-9519-209dec7e3991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {'HepG2':clean_data(hepg2_df), 'K562':clean_data(k562_df)}\n",
    "\n",
    "target_column = 'target_traveling.ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00c5ddf-2fc9-45f1-9fea-80bb2ec4b867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {'HepG2':{'alpha':2800},'K562':{'alpha':2800}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c94870a5-1365-4009-9642-81951dd911a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/06/06-20:55:09]- First evaluation, 50/50 train/test split: K562\n",
      "[2023/06/06-20:55:10]- Using hyperparameters:  {'alpha': 2800}\n",
      "[2023/06/06-20:55:10]- Train score:  0.739\n",
      "[2023/06/06-20:55:10]- Test score:  0.601\n",
      "[2023/06/06-20:55:10]-\n"
     ]
    }
   ],
   "source": [
    "for cell_line in ('K562',):\n",
    "\n",
    "    print('First evaluation, 50/50 train/test split:', cell_line)\n",
    "    \n",
    "    df = data[cell_line]\n",
    "    \n",
    "    y = df[target_column]\n",
    "    \n",
    "    X = df.drop(columns=target_column)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.5, random_state=1)\n",
    "    \n",
    "    X_train, X_test = normalize_features(X_train, X_test)\n",
    "    \n",
    "    if len(best_params[cell_line])==0:\n",
    "    \n",
    "        print('Looking for optimal hyperparameters...')\n",
    "\n",
    "        model = hpp_search(X_train, y_train)\n",
    "        \n",
    "        best_params[cell_line] = model.best_params_\n",
    "        \n",
    "        save_model(model,'train_on_half_' + cell_line + '_hpp_search' )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        model = Model(**best_params[cell_line],random_state=1)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    print('Using hyperparameters: ', best_params[cell_line])\n",
    "    \n",
    "    train_score = model.score(X_train, y_train)\n",
    "    \n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print('Train score: ', round(train_score,3))\n",
    "\n",
    "    print('Test score: ', round(test_score,3))\n",
    "    \n",
    "    #compute_shap_values(model, X_test, 'train_on_' + cell_line + '_test_on_' + cell_line + '_shapley_values')\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c7ef03e-cd2d-44a5-8050-13f87280488c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#with open(project_dir + '/K562_50_50_preds/' + 'linear_regression.pickle', 'wb') as f:\n",
    "#     pickle.dump({'y_true':y_test, 'y_pred':y_pred},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff088b81-b868-4706-830e-31d516082495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c322ccd7-fc07-4a4c-9867-9d155f6b0e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_features = set(data['HepG2'].columns).intersection(set(data['K562'].columns))\n",
    "common_features.remove(target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e2ee9bf-941f-4b5d-88d5-525d2430ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_genes = set(data['HepG2'].index).intersection(set(data['K562'].index))\n",
    "\n",
    "unique_genes = {'HepG2':set(data['HepG2'].index).difference(set(data['K562'].index)),\n",
    "               'K562':set(data['K562'].index).difference(set(data['HepG2'].index))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ead7bfeb-1e1e-4540-ba20-5e250764b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_common = {'HepG2':{'alpha':2800},'K562':{'alpha':2800}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e3b1316-3b4e-41dd-bcb2-f4815545fea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second evaluation, train on  HepG2  evaluate on  K562\n",
      "Using best hyperparameters:  {'alpha': 2800}\n",
      "Train score:  0.603\n",
      "Test score:  0.422\n",
      "Test score on common genes:  0.241\n",
      "Test score on genes unique for the test cell line (K562): 0.477\n",
      "\n",
      "Second evaluation, train on  K562  evaluate on  HepG2\n",
      "Using best hyperparameters:  {'alpha': 2800}\n",
      "Train score:  0.664\n",
      "Test score:  0.445\n",
      "Test score on common genes:  0.377\n",
      "Test score on genes unique for the test cell line (HepG2): 0.451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_cell_line, test_cell_line in (('HepG2','K562'), ('K562','HepG2')):\n",
    "\n",
    "    print('Second evaluation, train on ', train_cell_line,' evaluate on ', test_cell_line )\n",
    "    \n",
    "    train_df = data[train_cell_line]\n",
    "    \n",
    "    y_train = train_df[target_column]\n",
    "    X_train = train_df[common_features]\n",
    "    \n",
    "    test_df = data[test_cell_line]\n",
    "    \n",
    "    y_test = test_df[target_column]\n",
    "    X_test = test_df[common_features]\n",
    "    \n",
    "    X_train, X_test = normalize_features(X_train, X_test)\n",
    "    \n",
    "    if len(best_params_common[train_cell_line])==0:\n",
    "    \n",
    "        print('Looking for optimal hyperparameters...')\n",
    "    \n",
    "        model = hpp_search(X_train, y_train)\n",
    "        \n",
    "        best_params_common[train_cell_line] = model.best_params_\n",
    "        \n",
    "        save_model(model,'train_on_full_' + train_cell_line + '_hpp_search' )\n",
    "\n",
    "    else:\n",
    "        \n",
    "        model = Model(**best_params_common[train_cell_line],random_state=1)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    print('Using hyperparameters: ', best_params_common[train_cell_line])\n",
    "    \n",
    "    train_score = model.score(X_train, y_train)\n",
    "    \n",
    "    test_score = model.score(X_test, y_test)\n",
    "    \n",
    "    print('Train score: ', round(train_score,3))\n",
    "\n",
    "    print('Test score: ', round(test_score,3))\n",
    "    \n",
    "    test_score_common = model.score(X_test.loc[X_test.index.isin(common_genes)], y_test.loc[y_test.index.isin(common_genes)])\n",
    "\n",
    "    print('Test score on common genes: ', round(test_score_common,3))\n",
    "    \n",
    "    test_score_unique = model.score(X_test.loc[X_test.index.isin(unique_genes[test_cell_line])], y_test.loc[y_test.index.isin(unique_genes[test_cell_line])])\n",
    "\n",
    "    print('Test score on genes unique for the test cell line', '('+test_cell_line+'):', round(test_score_unique,3))\n",
    "    \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
